{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-491e59aec56791ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Workflow lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cade46b91b256c60",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib as mpl\n",
    "import re  # regular expressions\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import plotting_extent\n",
    "#from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "#from shapely.geometry import mapping\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "import earthpy.mask as em\n",
    "\n",
    "\n",
    "os.chdir(os.path.join(et.io.HOME, 'earth-analytics', 'data'))\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Landsat Data For Cold Springs\n",
    "\n",
    "In the cell or cells below open and process your Landsat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/leahwasser/earth-analytics/data/earthpy-downloads/landsat-coldsprings-hw'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Landsat data\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/21941085\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start With Pseudocoding\n",
    "\n",
    "Coding can seem daunting when you are starting from scratch. Start with what you \n",
    "know - English or whatever your native language is! Write out the steps as comments\n",
    "FIRST. \n",
    "\n",
    "In this case, You know that you have two directories of landsat scenes to process in this case.\n",
    "This will likely mean you will want to loop through and process each scene. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To begin create your pseudo code\n",
    "\n",
    "# High level\n",
    "\n",
    "# First create the high level loop to loop through each landsat directory of tif files (each scene)\n",
    "# Get all directories  - remember that getting a list makes things more scalabe\n",
    "# Loop through this list and\n",
    "# get all tif files in the directory\n",
    "# open / crop the files\n",
    "# stack the files - in this case you will want to use many different bands for the 2 veg indices\n",
    "\n",
    "# Mask the data (cloud mask)\n",
    "\n",
    "# Calculate NDVI\n",
    "\n",
    "# Calculate NBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Paths with Empty Loops\n",
    "Let's start with an empty loop. You could also start with the code but i like \n",
    "starting with an EMPTY loop to ensure I can access my directories properly! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/\n",
      "earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "# view subdirectories of data\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "# Open fire boundary\n",
    "fire_boundary_path = os.path.join(\"cold-springs-fire\",\n",
    "                                  \"vector_layers\",\n",
    "                                  \"fire-boundary-geomac\",\n",
    "                                  \"co_cold_springs_20160711_2200_dd83.shp\")\n",
    "fire_boundary = gpd.read_file(fire_boundary_path)\n",
    "\n",
    "# Test that the loop works as you think it should on the directories\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    print(landsat_dir)\n",
    "    # Get all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Paths to Extract Metadata\n",
    "\n",
    "Ok great - my loop is printing out two paths to the two scenes that i want to \n",
    "process. things are so far working as i'd like them to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/\n",
      "scene name:  LC080340322016062101T1-SC20200306230017\n",
      "date:  20160621\n",
      "\n",
      "\n",
      "path:  earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/\n",
      "scene name:  LC080340322016072301T1-SC20200306230205\n",
      "date:  20160723\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_pixel_qa.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_radsat_qa.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_aerosol.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band1.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band2.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band3.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band4.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band5.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band6.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016072301T1-SC20200306230205/LC08_L1TP_034032_20160723_20180131_01_T1_sr_band7.tif']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the loop works as you think it should on the directories\n",
    "# Begin to collect metadata that you will need from the path / file names\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    print(\"path: \", landsat_dir)\n",
    "    # Get the landsat scene name / directory\n",
    "    landsat_scene = os.path.basename(os.path.normpath(landsat_dir))\n",
    "    print(\"scene name: \", landsat_scene)\n",
    "    # Get the date from the scene name\n",
    "    print(\"date: \", landsat_scene[10:18])\n",
    "    # Create list of all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Code to Your PseudoCode\n",
    "Now you can start to work through adding code to your pseudocode. Take it \n",
    "step by step and think about potential issues that you may encounter in each step.\n",
    "\n",
    "Below you can see the code filled in - in between each comment which comes from the pseudo code.\n",
    "\n",
    "Developing the example below was a process:\n",
    "\n",
    "1. Create your pseudo code for the steps that you want to perform \n",
    "2. Create your EMPTY outer loop as a test to implement this across multiple directories (above)\n",
    "3. Begin to add code below each line of pseudo code. as you add your code:\n",
    "    1. Consider the inputs and ouputs of each function (use help(function_name) to help with this. \n",
    "    2. Consider where things could fail and add tests using try: statements or conditionals (`if` statements)\n",
    "    \n",
    "Now you have a few options. You can create the loop first and add code incrementally.\n",
    "You could also create the loop AFTEr writing out your code. \n",
    "\n",
    "A nice middle ground is to create your loop but only loop through one directory to begin with. \n",
    "Create your workflow. Then combine the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band1_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band2_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band3_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band4_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band5_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band6_crop.tif',\n",
       " 'earthpy-downloads/landsat-coldsprings-hw/LC080340322016062101T1-SC20200306230017/cropped/LC08_L1TP_034032_20160621_20170221_01_T1_sr_band7_crop.tif']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "\n",
    "# First create the high level loop to loop through each landsat directory of tif files (each scene)\n",
    "\n",
    "# Get all directories  - remember that getting a list makes things more scalabe\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "# Create a loop variable that you can use to run your code for a single directory\n",
    "landsat_dir = all_dirs[0]\n",
    "# Loop through this list - commenting out the loop for now and just focusing on the workflow! \n",
    "#for landsat_dir in all_dirs:\n",
    "all_files = []\n",
    "\n",
    "# Get all tif files in the directory\n",
    "all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "# open / crop the files - this actually requires several steps including\n",
    "# 1. creating an output crop path,\n",
    "# 2. opening up the fire boundary to crop\n",
    "# 3. Cropping the data\n",
    "if not os.path.exists(crop_path):\n",
    "    os.mkdir(crop_path)\n",
    "\n",
    "with rio.open(all_files[0]) as src:\n",
    "    fire_bound_reproject = fire_boundary.to_crs(src.crs)\n",
    "\n",
    "es.crop_all(raster_paths=all_files,\n",
    "            output_dir=crop_path,\n",
    "            geoms=fire_bound_reproject,\n",
    "            overwrite=True)\n",
    "# Get a list of bands to stack\n",
    "sorted(glob(crop_path + \"/*band*.tif\"))\n",
    "\n",
    "# Stack the bands for NDVI and NBR calculation\n",
    "\n",
    "\n",
    "# Mask clouds from the stacked bands\n",
    "\n",
    "# 1. open the qa layer\n",
    "\n",
    "\n",
    "# Generate list of values to mask using the pixel qa layer\n",
    "\n",
    "\n",
    "# 2. mask the numpy array\n",
    "# Create test to ensure the values are in the mask qa layer\n",
    "\n",
    "# Perform the steps below for each landsat scene\n",
    "# Because we are going to need several bands to calculate NDVI and NBR let's crop them all with es.crop_all\n",
    "\n",
    "\n",
    "# Clean data (clouds and no data values)\n",
    "\n",
    "# Calculate nbr\n",
    "\n",
    "# Calculate dNBR from pre-post fire nbr\n",
    "\n",
    "# Reclassify dnbr to create final plot\n",
    "\n",
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no pixels to mask\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "\n",
    "# First create the high level loop to loop through each landsat directory of tif files (each scene)\n",
    "\n",
    "# Get all directories  - remember that getting a list makes things more scalabe\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "# Loop through this list\n",
    "\n",
    "all_files = []\n",
    "# print(landsat_dir)\n",
    "# Get all tif files in the directory\n",
    "all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "# open / crop the files - this actually requires several steps including\n",
    "# 1. creating an output crop path,\n",
    "# 2. opening up the fire boundary to crop\n",
    "# 3. Cropping the data\n",
    "if not os.path.exists(crop_path):\n",
    "    os.mkdir(crop_path)\n",
    "\n",
    "with rio.open(all_files[0]) as src:\n",
    "    fire_bound_reproject = fire_boundary.to_crs(src.crs)\n",
    "\n",
    "es.crop_all(raster_paths=all_files,\n",
    "            output_dir=crop_path,\n",
    "            geoms=fire_bound_reproject,\n",
    "            overwrite=True)\n",
    "# Get a list of bands to stack\n",
    "all_bands = sorted(glob(crop_path + \"/*band*.tif\"))\n",
    "\n",
    "# Stack the bands for NDVI and NBR calculation\n",
    "landsat_bands, landsat_meta = es.stack(all_bands)\n",
    "\n",
    "# Mask clouds from the stacked bands\n",
    "\n",
    "# 1. open the qa layer\n",
    "pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "with rio.open(pixel_qa_path[0]) as src:\n",
    "    mask_arr = src.read(1)\n",
    "\n",
    "# Generate list of values to mask using the pixel qa layer\n",
    "high_cloud_confidence = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"High Cloud Confidence\"]\n",
    "cloud = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud\"]\n",
    "cloud_shadow = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud Shadow\"]\n",
    "all_masked_values = cloud_shadow + cloud + high_cloud_confidence\n",
    "\n",
    "# 2. mask the numpy array\n",
    "# Create test to ensure the values are in the mask qa layer\n",
    "if any(i in np.unique(mask_arr) for i in all_masked_values):\n",
    "    landsat_masked_bands = em.mask_pixels(landsat_bands,\n",
    "                                          mask_arr,\n",
    "                                          vals=all_masked_values)\n",
    "else:\n",
    "    print(\"There are no pixels to mask\")\n",
    "\n",
    "# Perform the steps below for each landsat scene\n",
    "# Because we are going to need several bands to calculate NDVI and NBR let's crop them all with es.crop_all\n",
    "\n",
    "\n",
    "# Clean data (clouds and no data values)\n",
    "\n",
    "# Calculate nbr\n",
    "\n",
    "# Calculate dNBR from pre-post fire nbr\n",
    "\n",
    "# Reclassify dnbr to create final plot\n",
    "\n",
    "# Plot data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have setup your code and it works on a scene, or within your loop you \n",
    "can think about making it modular. I often look at my code and find steps that \n",
    "are related that might pair nicely together in a function. Well-named Functions will \n",
    "make your code easier to read and trouble shoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "\n",
    "# First create the high level loop to loop through each landsat directory of tif files (each scene)\n",
    "\n",
    "# Get all directories  - remember that getting a list makes things more scalabe\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "# Loop through this list\n",
    "\n",
    "\n",
    "all_files = []\n",
    "# print(landsat_dir)\n",
    "# Get all tif files in the directory\n",
    "all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "# BEGIN FUNCTION that crops and returns a cropped stacked array of bands\n",
    "# open / crop the files - this actually requires several steps including\n",
    "# 1. creating an output crop path,\n",
    "# 2. opening up the fire boundary to crop\n",
    "# 3. Cropping the data\n",
    "if not os.path.exists(crop_path):\n",
    "    os.mkdir(crop_path)\n",
    "\n",
    "with rio.open(all_files[0]) as src:\n",
    "    fire_bound_reproject = fire_boundary.to_crs(src.crs)\n",
    "\n",
    "es.crop_all(raster_paths=all_files,\n",
    "            output_dir=crop_path,\n",
    "            geoms=fire_bound_reproject,\n",
    "            overwrite=True)\n",
    "# Get a list of bands to stack\n",
    "all_bands = sorted(glob(crop_path + \"/*band*.tif\"))\n",
    "\n",
    "# Stack the bands for NDVI and NBR calculation\n",
    "landsat_bands, landsat_meta = es.stack(all_bands)\n",
    "# END FUNCTION that crops and returns a stack...\n",
    "\n",
    "# BEGIN MASK FUNCTION\n",
    "# Mask clouds from the stacked bands\n",
    "\n",
    "# 1. open the qa layer\n",
    "pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "with rio.open(pixel_qa_path[0]) as src:\n",
    "    mask_arr = src.read(1)\n",
    "\n",
    "# Cloud mask values\n",
    "high_cloud_confidence = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"High Cloud Confidence\"]\n",
    "cloud = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud\"]\n",
    "cloud_shadow = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud Shadow\"]\n",
    "\n",
    "all_masked_values = cloud_shadow + cloud + high_cloud_confidence\n",
    "# 2. mask the numpy array\n",
    "# Create test to ensure the values are in the mask qa layer\n",
    "if any(i in np.unique(mask_arr) for i in all_masked_values):\n",
    "    landsat_masked_bands = em.mask_pixels(landsat_bands,\n",
    "                                          mask_arr,\n",
    "                                          vals=all_masked_values)\n",
    "else:\n",
    "    print(\"There are no pixels to mask\")\n",
    "# END MASK FUNCTION\n",
    "\n",
    "\n",
    "# Perform the steps below for each landsat scene\n",
    "# Because we are going to need several bands to calculate NDVI and NBR let's crop them all with es.crop_all\n",
    "\n",
    "\n",
    "# Clean data (clouds and no data values)\n",
    "\n",
    "# Calculate nbr\n",
    "\n",
    "# Calculate dNBR from pre-post fire nbr\n",
    "\n",
    "# Reclassify dnbr to create final plot\n",
    "\n",
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "\n",
    "# First create the high level loop to loop through each landsat directory of tif files (each scene)\n",
    "\n",
    "# Get all directories  - remember that getting a list makes things more scalabe\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "# Loop through this list\n",
    "\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    # print(landsat_dir)\n",
    "    # Get all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "    crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "    # BEGIN FUNCTION that crops and returns a cropped stacked array of bands\n",
    "    # open / crop the files - this actually requires several steps including\n",
    "    # 1. creating an output crop path,\n",
    "    # 2. opening up the fire boundary to crop\n",
    "    # 3. Cropping the data\n",
    "    if not os.path.exists(crop_path):\n",
    "        os.mkdir(crop_path)\n",
    "\n",
    "    with rio.open(all_files[0]) as src:\n",
    "        fire_bound_reproject = fire_boundary.to_crs(src.crs)\n",
    "\n",
    "    es.crop_all(raster_paths=all_files,\n",
    "                output_dir=crop_path,\n",
    "                geoms=fire_bound_reproject,\n",
    "                overwrite=True)\n",
    "    # Get a list of bands to stack\n",
    "    all_bands = sorted(glob(crop_path + \"/*band*.tif\"))\n",
    "\n",
    "    # Stack the bands for NDVI and NBR calculation\n",
    "    landsat_bands, landsat_meta = es.stack(all_bands)\n",
    "    # END FUNCTION that crops and returns a stack...\n",
    "\n",
    "    # BEGIN MASK FUNCTION\n",
    "    # Mask clouds from the stacked bands\n",
    "\n",
    "    # 1. open the qa layer\n",
    "    pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "    with rio.open(pixel_qa_path[0]) as src:\n",
    "        mask_arr = src.read(1)\n",
    "\n",
    "    # Cloud mask values\n",
    "    high_cloud_confidence = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"High Cloud Confidence\"]\n",
    "    cloud = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud\"]\n",
    "    cloud_shadow = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud Shadow\"]\n",
    "\n",
    "    all_masked_values = cloud_shadow + cloud + high_cloud_confidence\n",
    "    # 2. mask the numpy array\n",
    "    # Create test to ensure the values are in the mask qa layer\n",
    "    if any(i in np.unique(mask_arr) for i in all_masked_values):\n",
    "        landsat_masked_bands = em.mask_pixels(landsat_bands,\n",
    "                                              mask_arr,\n",
    "                                              vals=all_masked_values)\n",
    "    else:\n",
    "        print(\"There are no pixels to mask\")\n",
    "    # END MASK FUNCTION\n",
    "\n",
    "\n",
    "# Perform the steps below for each landsat scene\n",
    "# Because we are going to need several bands to calculate NDVI and NBR let's crop them all with es.crop_all\n",
    "\n",
    "\n",
    "# Clean data (clouds and no data values)\n",
    "\n",
    "# Calculate nbr\n",
    "\n",
    "# Calculate dNBR from pre-post fire nbr\n",
    "\n",
    "# Reclassify dnbr to create final plot\n",
    "\n",
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_stack_data(files_to_crop, crop_path, crop_bound):\n",
    "    \"\"\"Crops a set of tif files and saves them in a crop directory.\n",
    "    Returns a stacked numpy array of bands\"\"\"\n",
    "    if not os.path.exists(crop_path):\n",
    "        os.mkdir(crop_path)\n",
    "\n",
    "    with rio.open(all_files[0]) as src:\n",
    "        fire_bound_reproject = fire_boundary.to_crs(src.crs)\n",
    "\n",
    "    es.crop_all(raster_paths=all_files,\n",
    "                output_dir=crop_path,\n",
    "                geoms=fire_bound_reproject,\n",
    "                overwrite=True)\n",
    "    # Get a list of bands to stack\n",
    "    all_bands = sorted(glob(crop_path + \"/*band*.tif\"))\n",
    "\n",
    "    # Stack the bands for NDVI and NBR calculation\n",
    "    return es.stack(all_bands)\n",
    "\n",
    "\n",
    "def mask_data(arr, path_to_qa):\n",
    "    \"\"\"Function that masks a numpy array using a cloud qa layer\"\"\"\n",
    "\n",
    "    # 1. open the qa layer\n",
    "    with rio.open(pixel_qa_path[0]) as src:\n",
    "        mask_arr = src.read(1)\n",
    "\n",
    "    # Cloud mask values\n",
    "    high_cloud_confidence = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"High Cloud Confidence\"]\n",
    "    cloud = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud\"]\n",
    "    cloud_shadow = em.pixel_flags[\"pixel_qa\"][\"L8\"][\"Cloud Shadow\"]\n",
    "\n",
    "    all_masked_values = cloud_shadow + cloud + high_cloud_confidence\n",
    "    # 2. mask the numpy array\n",
    "    # Create test to ensure the values are in the mask qa layer\n",
    "    if any(i in np.unique(mask_arr) for i in all_masked_values):\n",
    "        landsat_masked_bands = em.mask_pixels(landsat_bands,\n",
    "                                              mask_arr,\n",
    "                                              vals=all_masked_values)\n",
    "        return landsat_masked_bands\n",
    "    else:\n",
    "        print(\"There are no pixels to mask\")\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the functions notice how much easier the code is to read!\n",
    "At this point you have a working loop and you can continue to add pieces of \n",
    "your workflow.\n",
    "\n",
    "Functions are a nice way to organize your work because they allow you to \n",
    "modularize your workflow, extracting steps into individual components that you \n",
    "can test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"earthpy-downloads\", \"landsat-coldsprings-hw\")\n",
    "# view subdirectories of data\n",
    "all_dirs = glob(data_path + \"/*/\")\n",
    "\n",
    "\n",
    "#####\n",
    "# High level\n",
    "\n",
    "# First create the high level loop to loop through 1) each landsat directory and then 2) the files\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    # print(landsat_dir)\n",
    "    # Get all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "    crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "    # crop & stack data - note that the no data values have NOT been accounted for yet\n",
    "    landsat_arr, landsat_meta = crop_stack_data(files_to_crop=all_files,\n",
    "                                                crop_path=crop_path,\n",
    "                                                crop_bound=fire_boundary)\n",
    "\n",
    "    # Mask data\n",
    "    pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "    landsat_mask = mask_data(landsat_arr, pixel_qa_path)\n",
    "\n",
    "\n",
    "# Calculate nbr\n",
    "\n",
    "# Calculate dNBR from pre-post fire nbr\n",
    "\n",
    "# Reclassify dnbr to create final plot\n",
    "\n",
    "# Plot data\n",
    "\n",
    "\n",
    "# Get list of all tif files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code is simpler however there is a remaining issue. the loop processes \n",
    "the data for each site but it overwrites the resulting data each time which \n",
    "means that you will not be able to calculate NDVI difference. \n",
    "\n",
    "Here you have a few options.\n",
    "\n",
    "1. Create a list of masked arrays and use this list: This could work well and it will scale. It will however require you to keep track of the array index in the list so keep that in mind.  \n",
    "2. If your loop is small you could create custom variable names for each returned array.\n",
    "3. You could write out intermediate stacked tif files if you want. Sometimes this option is nice when you have a big workflow that may need to be \"Started\" somewhere in the middle at some point rather than from the beginning.\n",
    "4. Create a dictionary with a custom key name (this is an ideal option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the high level loop to loop through 1) each landsat directory and then 2) the files\n",
    "landsat_data = {}\n",
    "\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    # print(landsat_dir)\n",
    "    # Get all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "    crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "    # crop & stack data\n",
    "    landsat_arr, landsat_meta = crop_stack_data(files_to_crop=all_files,\n",
    "                                                crop_path=crop_path,\n",
    "                                                crop_bound=fire_boundary)\n",
    "\n",
    "    # Mask data\n",
    "    pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "\n",
    "    # Get dir name - you could also chose to just use the date as the scene dictionary key\n",
    "    \n",
    "    landsat_scene = os.path.basename(os.path.normpath(landsat_dir))\n",
    "    scene_date = landsat_scene[10:18]\n",
    "\n",
    "    landsat_data[scene_date] = mask_data(landsat_arr, pixel_qa_path)\n",
    "\n",
    "\n",
    "landsat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data as a visual check\n",
    "ep.plot_bands(landsat_data[\"20160723\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you have a working loop that processes, crops, and stacks your \n",
    "data. You can at any time add additional cleaning steps to existing functions \n",
    "or you could create new functions and add those to the workflow. \n",
    "\n",
    "Next, you may want to calculate your vegetation indices using functions or steps.\n",
    "Below two additional objects are created for ndvi and nbr respectively. Note that \n",
    "you could combine these into one dict or keep them separate depending upon \n",
    "your workflow! Or maybe you decided that you do'nt need the dict of cleaned \n",
    "data. you ONLY want the dict for NDVI and NBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested dictionary can be used to store information hierarchically as an option\n",
    "\n",
    "veg_indices = {}\n",
    "\n",
    "veg_indices[\"date\"] = {\"ndvi\": .8, \"nbr\": .8}\n",
    "                       \n",
    "veg_indices[\"date\"][\"ndvi\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you create a nested dictionary to store information. You can then use this to calculate\n",
    "your difference raster which you need for the final plots in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the high level loop to loop through 1) each landsat directory and then 2) the files\n",
    "landsat_data = {}\n",
    "veg_index = {}\n",
    "\n",
    "for landsat_dir in all_dirs:\n",
    "    all_files = []\n",
    "    # print(landsat_dir)\n",
    "    # Get all tif files in the directory\n",
    "    all_files = sorted(glob(landsat_dir + \"/*.tif\"))\n",
    "    crop_path = os.path.join(landsat_dir, \"cropped\")\n",
    "\n",
    "    # crop & stack data\n",
    "    landsat_arr, landsat_meta = crop_stack_data(files_to_crop=all_files,\n",
    "                                                crop_path=crop_path,\n",
    "                                                crop_bound=fire_boundary)\n",
    "\n",
    "    # Mask data\n",
    "    pixel_qa_path = glob(crop_path + \"/*pixel_qa*.tif\")\n",
    "\n",
    "    # Get dir name - you could also chose to just use the date as the scene dictionary key\n",
    "    \n",
    "    landsat_scene = os.path.basename(os.path.normpath(landsat_dir))\n",
    "    scene_date = landsat_scene[10:18]\n",
    "\n",
    "    cleaned_landsat = mask_data(landsat_arr, pixel_qa_path)\n",
    "    \n",
    "    # Calculate NDVI - note that the way this is written, it will only work for \n",
    "    # landsat / ndvi as the band numbers are hard coded.\n",
    "    # Also note that the bands below are not necessarily correct.\n",
    "    veg_index[scene_date] = {\"ndvi\": es.normalized_diff(cleaned_landsat[4], cleaned_landsat[3]),\n",
    "                       \"nbr\": (cleaned_landsat[4], cleaned_landsat[3])} \n",
    "    \n",
    "    # Calculate difference\n",
    "\n",
    "\n",
    "veg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.plot_bands(veg_index[\"20160723\"][\"ndvi\"],\n",
    "             scale=False, cmap = \"Greens\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
